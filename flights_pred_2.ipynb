{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU2n0pG5Mpvq",
        "outputId": "a138518b-5e1a-415a-8b11-bbed1039f86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "!pip install catboost xgboost --quiet\n",
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML & preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Models\n",
        "from catboost import CatBoostRegressor, CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('default')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load flight dataset\n",
        "df = pd.read_csv('flights_sample_3m.csv', parse_dates=['FL_DATE'])\n",
        "\n",
        "# Basic overview\n",
        "print(\"Dataset Overview\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Date range: {df['FL_DATE'].min()} to {df['FL_DATE'].max()}\")\n",
        "\n",
        "# Quick inspection\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nColumn info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Check for potential data leakage\n",
        "delay_cols = [col for col in df.columns if 'DELAY' in col.upper()]\n",
        "print(\"\\nPotential leakage columns:\")\n",
        "for col in delay_cols:\n",
        "    print(f\"- {col}\")\n",
        "\n",
        "print(f\"\\nDataset loaded successfully with {len(df):,} records\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRRxeFBBNdVq",
        "outputId": "1f116248-9817-40ad-c56c-89a73fa15731"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Overview\n",
            "Shape: (3000000, 32)\n",
            "Date range: 2019-01-01 00:00:00 to 2023-08-31 00:00:00\n",
            "\n",
            "First 5 rows:\n",
            "     FL_DATE                AIRLINE                AIRLINE_DOT AIRLINE_CODE  \\\n",
            "0 2019-01-09  United Air Lines Inc.  United Air Lines Inc.: UA           UA   \n",
            "1 2022-11-19   Delta Air Lines Inc.   Delta Air Lines Inc.: DL           DL   \n",
            "2 2022-07-22  United Air Lines Inc.  United Air Lines Inc.: UA           UA   \n",
            "3 2023-03-06   Delta Air Lines Inc.   Delta Air Lines Inc.: DL           DL   \n",
            "4 2020-02-23       Spirit Air Lines       Spirit Air Lines: NK           NK   \n",
            "\n",
            "   DOT_CODE  FL_NUMBER ORIGIN          ORIGIN_CITY DEST  \\\n",
            "0     19977       1562    FLL  Fort Lauderdale, FL  EWR   \n",
            "1     19790       1149    MSP      Minneapolis, MN  SEA   \n",
            "2     19977        459    DEN           Denver, CO  MSP   \n",
            "3     19790       2295    MSP      Minneapolis, MN  SFO   \n",
            "4     20416        407    MCO          Orlando, FL  DFW   \n",
            "\n",
            "               DEST_CITY  ...  DIVERTED  CRS_ELAPSED_TIME  ELAPSED_TIME  \\\n",
            "0             Newark, NJ  ...       0.0             186.0         176.0   \n",
            "1            Seattle, WA  ...       0.0             235.0         236.0   \n",
            "2        Minneapolis, MN  ...       0.0             118.0         112.0   \n",
            "3      San Francisco, CA  ...       0.0             260.0         285.0   \n",
            "4  Dallas/Fort Worth, TX  ...       0.0             181.0         182.0   \n",
            "\n",
            "   AIR_TIME  DISTANCE  DELAY_DUE_CARRIER  DELAY_DUE_WEATHER  DELAY_DUE_NAS  \\\n",
            "0     153.0    1065.0                NaN                NaN            NaN   \n",
            "1     189.0    1399.0                NaN                NaN            NaN   \n",
            "2      87.0     680.0                NaN                NaN            NaN   \n",
            "3     249.0    1589.0                0.0                0.0           24.0   \n",
            "4     153.0     985.0                NaN                NaN            NaN   \n",
            "\n",
            "   DELAY_DUE_SECURITY  DELAY_DUE_LATE_AIRCRAFT  \n",
            "0                 NaN                      NaN  \n",
            "1                 NaN                      NaN  \n",
            "2                 NaN                      NaN  \n",
            "3                 0.0                      0.0  \n",
            "4                 NaN                      NaN  \n",
            "\n",
            "[5 rows x 32 columns]\n",
            "\n",
            "Column info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000000 entries, 0 to 2999999\n",
            "Data columns (total 32 columns):\n",
            " #   Column                   Dtype         \n",
            "---  ------                   -----         \n",
            " 0   FL_DATE                  datetime64[ns]\n",
            " 1   AIRLINE                  object        \n",
            " 2   AIRLINE_DOT              object        \n",
            " 3   AIRLINE_CODE             object        \n",
            " 4   DOT_CODE                 int64         \n",
            " 5   FL_NUMBER                int64         \n",
            " 6   ORIGIN                   object        \n",
            " 7   ORIGIN_CITY              object        \n",
            " 8   DEST                     object        \n",
            " 9   DEST_CITY                object        \n",
            " 10  CRS_DEP_TIME             int64         \n",
            " 11  DEP_TIME                 float64       \n",
            " 12  DEP_DELAY                float64       \n",
            " 13  TAXI_OUT                 float64       \n",
            " 14  WHEELS_OFF               float64       \n",
            " 15  WHEELS_ON                float64       \n",
            " 16  TAXI_IN                  float64       \n",
            " 17  CRS_ARR_TIME             int64         \n",
            " 18  ARR_TIME                 float64       \n",
            " 19  ARR_DELAY                float64       \n",
            " 20  CANCELLED                float64       \n",
            " 21  CANCELLATION_CODE        object        \n",
            " 22  DIVERTED                 float64       \n",
            " 23  CRS_ELAPSED_TIME         float64       \n",
            " 24  ELAPSED_TIME             float64       \n",
            " 25  AIR_TIME                 float64       \n",
            " 26  DISTANCE                 float64       \n",
            " 27  DELAY_DUE_CARRIER        float64       \n",
            " 28  DELAY_DUE_WEATHER        float64       \n",
            " 29  DELAY_DUE_NAS            float64       \n",
            " 30  DELAY_DUE_SECURITY       float64       \n",
            " 31  DELAY_DUE_LATE_AIRCRAFT  float64       \n",
            "dtypes: datetime64[ns](1), float64(19), int64(4), object(8)\n",
            "memory usage: 732.4+ MB\n",
            "None\n",
            "\n",
            "Potential leakage columns:\n",
            "- DEP_DELAY\n",
            "- ARR_DELAY\n",
            "- DELAY_DUE_CARRIER\n",
            "- DELAY_DUE_WEATHER\n",
            "- DELAY_DUE_NAS\n",
            "- DELAY_DUE_SECURITY\n",
            "- DELAY_DUE_LATE_AIRCRAFT\n",
            "\n",
            "Dataset loaded successfully with 3,000,000 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Legitimate features for arrival delay prediction\n",
        "legitimate_features = [\n",
        "    'AIRLINE', 'AIRLINE_CODE', 'ORIGIN', 'DEST', 'FL_NUMBER', 'DISTANCE',\n",
        "    'CRS_DEP_TIME', 'CRS_ARR_TIME', 'CRS_ELAPSED_TIME', 'FL_DATE',\n",
        "    'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF'\n",
        "]\n",
        "\n",
        "# Leaky features to exclude\n",
        "truly_leaky_features = [\n",
        "    'ARR_TIME', 'ARR_DELAY', 'WHEELS_ON', 'TAXI_IN', 'ELAPSED_TIME', 'AIR_TIME',\n",
        "    'DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS',\n",
        "    'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT'\n",
        "]\n",
        "\n",
        "print(\"Legitimate features:\")\n",
        "for f in legitimate_features:\n",
        "    print(f\"- {f}\")\n",
        "print(f\"Total: {len(legitimate_features)}\")\n",
        "\n",
        "print(\"\\nTrue data leakage (to remove):\")\n",
        "for f in truly_leaky_features:\n",
        "    print(f\"- {f}\")\n",
        "print(f\"Total: {len(truly_leaky_features)}\")\n",
        "\n",
        "# Clean dataset\n",
        "initial_size = len(df)\n",
        "df_clean = df[(df['CANCELLED'] != 1) & (df['DIVERTED'] != 1)].copy()\n",
        "\n",
        "critical_features = ['DEP_TIME', 'DEP_DELAY', 'ARR_DELAY', 'DISTANCE']\n",
        "df_clean.dropna(subset=critical_features, inplace=True)\n",
        "\n",
        "features_to_use = [c for c in legitimate_features if c in df_clean.columns]\n",
        "target_variable = 'ARR_DELAY'\n",
        "\n",
        "print(f\"\\nClean dataset:\")\n",
        "print(f\"Records: {len(df_clean):,}\")\n",
        "print(f\"Features: {len(features_to_use)}\")\n",
        "print(f\"Target: {target_variable}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyhfFjI4Q5eE",
        "outputId": "38c62d16-6a67-458d-d7a9-d55e10ce5b72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Legitimate features:\n",
            "- AIRLINE\n",
            "- AIRLINE_CODE\n",
            "- ORIGIN\n",
            "- DEST\n",
            "- FL_NUMBER\n",
            "- DISTANCE\n",
            "- CRS_DEP_TIME\n",
            "- CRS_ARR_TIME\n",
            "- CRS_ELAPSED_TIME\n",
            "- FL_DATE\n",
            "- DEP_TIME\n",
            "- DEP_DELAY\n",
            "- TAXI_OUT\n",
            "- WHEELS_OFF\n",
            "Total: 14\n",
            "\n",
            "True data leakage (to remove):\n",
            "- ARR_TIME\n",
            "- ARR_DELAY\n",
            "- WHEELS_ON\n",
            "- TAXI_IN\n",
            "- ELAPSED_TIME\n",
            "- AIR_TIME\n",
            "- DELAY_DUE_CARRIER\n",
            "- DELAY_DUE_WEATHER\n",
            "- DELAY_DUE_NAS\n",
            "- DELAY_DUE_SECURITY\n",
            "- DELAY_DUE_LATE_AIRCRAFT\n",
            "Total: 11\n",
            "\n",
            "Clean dataset:\n",
            "Records: 2,913,802\n",
            "Features: 14\n",
            "Target: ARR_DELAY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort data by date to ensure temporal order\n",
        "df_clean = df_clean.sort_values(['FL_DATE', 'AIRLINE', 'ORIGIN']).reset_index(drop=True)\n",
        "\n",
        "# Create time features if not exist\n",
        "if 'MONTH' not in df_clean.columns:\n",
        "    df_clean['MONTH'] = df_clean['FL_DATE'].dt.month\n",
        "    df_clean['DAY_OF_WEEK'] = df_clean['FL_DATE'].dt.dayofweek\n",
        "    df_clean['DAY_OF_YEAR'] = df_clean['FL_DATE'].dt.dayofyear\n",
        "\n",
        "# Keep only features that contributed in CatBoost top-15\n",
        "# Historical performance features\n",
        "df_clean['AIRLINE_HIST_DELAY'] = df_clean.groupby('AIRLINE')['DEP_DELAY'].expanding().mean().shift(1).reset_index(level=0, drop=True)\n",
        "df_clean['ROUTE_HIST_DELAY'] = (df_clean.assign(ROUTE_KEY=df_clean['ORIGIN'] + '_' + df_clean['DEST'])\n",
        "                                .groupby('ROUTE_KEY')['DEP_DELAY'].expanding().mean().shift(1)\n",
        "                                .reset_index(level=0, drop=True))\n",
        "\n",
        "# Fill NaN with overall mean\n",
        "overall_mean = df_clean['DEP_DELAY'].mean()\n",
        "for feature in ['AIRLINE_HIST_DELAY', 'ROUTE_HIST_DELAY']:\n",
        "    df_clean[feature] = df_clean[feature].fillna(overall_mean)\n",
        "\n",
        "# Keep only time features in top 15\n",
        "# DAY_OF_YEAR, DAY_OF_WEEK, DEP_HOUR, HOUR_SIN, HOUR_COS, IS_SUMMER, IS_PEAK_TRAVEL_DAY, IS_HOLIDAY_WEEK, ROUTE_FREQUENCY\n",
        "# Ensure these columns exist or create placeholders if needed\n",
        "time_features = ['DAY_OF_YEAR', 'DAY_OF_WEEK']\n",
        "for f in time_features:\n",
        "    if f not in df_clean.columns:\n",
        "        df_clean[f] = 0  # placeholder, compute properly later\n",
        "\n",
        "# Verify dataset shape\n",
        "print(f\"Final dataset after feature selection: {df_clean.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTSZuc95Ynly",
        "outputId": "d95f3169-90d9-4f69-eccd-e03f46cae871"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset after feature selection: (2913802, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Airline-standard delay categories\n",
        "def airline_delay_categories(delay):\n",
        "    if pd.isna(delay):\n",
        "        return 'Unknown'\n",
        "    elif delay <= 15:\n",
        "        return 'On_Time'\n",
        "    elif delay <= 60:\n",
        "        return 'Minor_Delay'\n",
        "    elif delay <= 240:\n",
        "        return 'Major_Delay'\n",
        "    else:\n",
        "        return 'Severe_Delay'\n",
        "\n",
        "# Apply categorization\n",
        "df_clean['DEP_DELAY_CATEGORY'] = df_clean['DEP_DELAY'].apply(airline_delay_categories)\n",
        "df_clean['ARR_DELAY_CATEGORY'] = df_clean['ARR_DELAY'].apply(airline_delay_categories)\n",
        "\n",
        "# Binary target: delayed if ARR_DELAY > 15 min\n",
        "df_clean['IS_DELAYED'] = (df_clean['ARR_DELAY'] > 15).astype(int)\n",
        "\n",
        "# Distribution summary\n",
        "category_dist = df_clean['ARR_DELAY_CATEGORY'].value_counts()\n",
        "for cat, cnt in category_dist.items():\n",
        "    print(f\"{cat}: {cnt:,} ({cnt/len(df_clean)*100:.1f}%)\")\n",
        "\n",
        "print(f\"Binary delayed flights: {df_clean['IS_DELAYED'].sum():,} ({df_clean['IS_DELAYED'].mean()*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfXLLh1aa1q6",
        "outputId": "e417bebb-0e70-4b90-e65c-bf3a2ce2a95b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On_Time: 2,398,513 (82.3%)\n",
            "Minor_Delay: 340,154 (11.7%)\n",
            "Major_Delay: 157,912 (5.4%)\n",
            "Severe_Delay: 17,223 (0.6%)\n",
            "Binary delayed flights: 515,289 (17.7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Time-based features from scheduled departure\n",
        "df_clean['DEP_HOUR'] = df_clean['CRS_DEP_TIME'] // 100\n",
        "df_clean['DEP_MINUTE'] = df_clean['CRS_DEP_TIME'] % 100\n",
        "\n",
        "# Temporal features\n",
        "df_clean['MONTH'] = df_clean['FL_DATE'].dt.month\n",
        "df_clean['DAY_OF_WEEK'] = df_clean['FL_DATE'].dt.dayofweek\n",
        "df_clean['IS_WEEKEND'] = (df_clean['DAY_OF_WEEK'] >= 5).astype(int)\n",
        "\n",
        "# Rush hour indicators\n",
        "df_clean['IS_MORNING_RUSH'] = ((df_clean['DEP_HOUR'] >= 6) & (df_clean['DEP_HOUR'] <= 9)).astype(int)\n",
        "df_clean['IS_EVENING_RUSH'] = ((df_clean['DEP_HOUR'] >= 16) & (df_clean['DEP_HOUR'] <= 19)).astype(int)\n",
        "\n",
        "# Seasonal indicators\n",
        "df_clean['IS_SUMMER'] = ((df_clean['MONTH'] >= 6) & (df_clean['MONTH'] <= 8)).astype(int)\n",
        "df_clean['IS_WINTER'] = ((df_clean['MONTH'] >= 12) | (df_clean['MONTH'] <= 2)).astype(int)\n",
        "\n",
        "# Distance categories\n",
        "df_clean['IS_SHORT_HAUL'] = (df_clean['DISTANCE'] <= 500).astype(int)\n",
        "df_clean['IS_LONG_HAUL'] = (df_clean['DISTANCE'] >= 1500).astype(int)\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_features = ['AIRLINE', 'ORIGIN', 'DEST']\n",
        "le_dict = {}\n",
        "for col in categorical_features:\n",
        "    if col in df_clean.columns:\n",
        "        le_dict[col] = LabelEncoder()\n",
        "        df_clean[col] = le_dict[col].fit_transform(df_clean[col].astype(str))\n",
        "\n",
        "# Normalize numerical features\n",
        "numerical_features = ['DISTANCE', 'CRS_ELAPSED_TIME', 'DEP_DELAY', 'TAXI_OUT', 'DEP_HOUR', 'DEP_MINUTE']\n",
        "features_to_scale = [col for col in numerical_features if col in df_clean.columns]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_clean[features_to_scale] = scaler.fit_transform(df_clean[features_to_scale])\n",
        "\n",
        "# Final feature set for modeling\n",
        "modeling_features = [\n",
        "    'AIRLINE', 'ORIGIN', 'DEST', 'DISTANCE',\n",
        "    'DEP_HOUR', 'MONTH', 'DAY_OF_WEEK', 'IS_WEEKEND',\n",
        "    'IS_MORNING_RUSH', 'IS_EVENING_RUSH', 'IS_SUMMER', 'IS_WINTER',\n",
        "    'IS_SHORT_HAUL', 'IS_LONG_HAUL'\n",
        "]\n",
        "final_features = [col for col in modeling_features if col in df_clean.columns]\n",
        "\n",
        "# Summary\n",
        "print(f\"Final feature set: {len(final_features)} features\")\n",
        "print(df_clean[final_features].head())\n",
        "print(f\"Dataset shape: {df_clean.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESgjzxbPR-w9",
        "outputId": "3325c3ed-1d75-4176-e2ca-abecc6582c34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature set: 14 features\n",
            "   AIRLINE  ORIGIN  DEST  DISTANCE  DEP_HOUR  MONTH  DAY_OF_WEEK  IS_WEEKEND  \\\n",
            "0        0      19    32 -0.698576  1.036579      1            1           0   \n",
            "1        0      19    10 -0.946298  0.415713      1            1           0   \n",
            "2        0      19   323  1.081290 -1.446887      1            1           0   \n",
            "3        0      19   201  2.603254  2.071357      1            1           0   \n",
            "4        0     108   323  1.894022  0.622668      1            1           0   \n",
            "\n",
            "   IS_MORNING_RUSH  IS_EVENING_RUSH  IS_SUMMER  IS_WINTER  IS_SHORT_HAUL  \\\n",
            "0                0                1          0          1              1   \n",
            "1                0                0          0          1              1   \n",
            "2                1                0          0          1              0   \n",
            "3                0                0          0          1              0   \n",
            "4                0                1          0          1              0   \n",
            "\n",
            "   IS_LONG_HAUL  \n",
            "0             0  \n",
            "1             0  \n",
            "2             0  \n",
            "3             1  \n",
            "4             1  \n",
            "Dataset shape: (2913802, 49)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cyclical time encoding\n",
        "df_clean['HOUR_SIN'] = np.sin(2 * np.pi * df_clean['DEP_HOUR'] / 24)\n",
        "df_clean['HOUR_COS'] = np.cos(2 * np.pi * df_clean['DEP_HOUR'] / 24)\n",
        "df_clean['DAY_OF_YEAR'] = df_clean['FL_DATE'].dt.dayofyear\n",
        "\n",
        "# Enhanced time period\n",
        "def enhanced_time_period(hour):\n",
        "    if pd.isna(hour): return 2\n",
        "    if 5 <= hour < 8: return 0\n",
        "    elif 8 <= hour < 12: return 1\n",
        "    elif 12 <= hour < 17: return 2\n",
        "    elif 17 <= hour < 21: return 3\n",
        "    else: return 4\n",
        "\n",
        "df_clean['TIME_PERIOD_ENHANCED'] = df_clean['DEP_HOUR'].apply(enhanced_time_period)\n",
        "\n",
        "# Travel patterns\n",
        "df_clean['IS_PEAK_TRAVEL_DAY'] = df_clean['DAY_OF_WEEK'].isin([4, 6]).astype(int)\n",
        "df_clean['IS_HOLIDAY_WEEK'] = df_clean['FL_DATE'].dt.isocalendar().week.isin([51, 52, 1, 25]).astype(int)\n",
        "\n",
        "# Airport congestion\n",
        "df_clean['DEP_HOUR_FLIGHTS'] = df_clean.groupby(['ORIGIN', 'DEP_HOUR'])['ORIGIN'].transform('count')\n",
        "\n",
        "# Hub and route indicators\n",
        "hubs = ['JFK', 'LAX', 'ORD', 'ATL', 'DFW', 'DEN']\n",
        "df_clean['IS_INTERNATIONAL_HUB'] = df_clean['ORIGIN'].isin(hubs).astype(int)\n",
        "df_clean['IS_TRANSCONTINENTAL'] = (df_clean['DISTANCE'] > 2500).astype(int)\n",
        "\n",
        "# Distance category\n",
        "def safe_distance_category(dist):\n",
        "    if pd.isna(dist): return 1\n",
        "    elif dist <= 500: return 0\n",
        "    elif dist <= 1000: return 1\n",
        "    elif dist <= 2000: return 2\n",
        "    else: return 3\n",
        "\n",
        "df_clean['DISTANCE_CAT'] = df_clean['DISTANCE'].apply(safe_distance_category)\n",
        "\n",
        "# Historical airline delay\n",
        "df_clean['AIRLINE_HISTORICAL_DELAY'] = df_clean.groupby('AIRLINE')['DEP_DELAY'].transform('mean')\n",
        "\n",
        "# Route frequency\n",
        "route_key = df_clean['ORIGIN'].astype(str) + '_' + df_clean['DEST'].astype(str)\n",
        "df_clean['ROUTE_FREQUENCY'] = route_key.map(route_key.value_counts()).fillna(1)\n",
        "\n",
        "# Hub flags for origin/destination\n",
        "df_clean['ORIGIN_IS_HUB'] = df_clean['ORIGIN'].isin(hubs).astype(int)\n",
        "df_clean['DEST_IS_HUB'] = df_clean['DEST'].isin(hubs).astype(int)\n",
        "\n",
        "# Update final features\n",
        "enhanced_features = final_features + [\n",
        "    'HOUR_SIN', 'HOUR_COS', 'DAY_OF_YEAR', 'TIME_PERIOD_ENHANCED',\n",
        "    'IS_PEAK_TRAVEL_DAY', 'IS_HOLIDAY_WEEK', 'DEP_HOUR_FLIGHTS',\n",
        "    'IS_INTERNATIONAL_HUB', 'IS_TRANSCONTINENTAL', 'DISTANCE_CAT',\n",
        "    'AIRLINE_HISTORICAL_DELAY', 'ROUTE_FREQUENCY', 'ORIGIN_IS_HUB', 'DEST_IS_HUB'\n",
        "]\n",
        "\n",
        "# Check for NaNs\n",
        "for feat in enhanced_features[len(final_features):]:\n",
        "    df_clean[feat].fillna(0, inplace=True)\n",
        "\n",
        "final_features = enhanced_features\n",
        "print(f\"Final feature count: {len(final_features)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joHqD6ABWOtg",
        "outputId": "bfad7d2c-f572-4bba-aa5f-7ea5960ec0ea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature count: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interaction features\n",
        "df_clean['AIRLINE_ORIGIN_COMBO'] = df_clean['AIRLINE'].astype(str) + '_' + df_clean['ORIGIN'].astype(str)\n",
        "df_clean['DISTANCE_TIME_RATIO'] = df_clean['DISTANCE'] / (df_clean['DEP_HOUR'] + 1)\n",
        "df_clean['WEEKEND_RUSH_COMBO'] = df_clean['IS_WEEKEND'] * df_clean['IS_MORNING_RUSH']\n",
        "\n",
        "# Rolling window features (7-day airline delay average)\n",
        "df_clean = df_clean.sort_values(['FL_DATE', 'AIRLINE'])\n",
        "df_clean['AIRLINE_7DAY_AVG'] = df_clean.groupby('AIRLINE')['DEP_DELAY'].transform(\n",
        "    lambda x: x.rolling(window=7, min_periods=1).mean().shift(1)\n",
        ")\n",
        "\n",
        "# Weather proxy features\n",
        "df_clean['WINTER_MORNING'] = df_clean['IS_WINTER'] * df_clean['IS_MORNING_RUSH']\n",
        "df_clean['SUMMER_EVENING'] = df_clean['IS_SUMMER'] * df_clean['IS_EVENING_RUSH']\n",
        "\n",
        "# Update final feature list\n",
        "additional_features = [\n",
        "    'AIRLINE_ORIGIN_COMBO', 'DISTANCE_TIME_RATIO', 'WEEKEND_RUSH_COMBO',\n",
        "    'AIRLINE_7DAY_AVG', 'WINTER_MORNING', 'SUMMER_EVENING'\n",
        "]\n",
        "\n",
        "final_features = final_features + additional_features"
      ],
      "metadata": {
        "id": "ZxExX-IyIa32"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features and target\n",
        "X = df_clean[final_features].copy()\n",
        "y = df_clean['ARR_DELAY'].copy()\n",
        "\n",
        "# Identify categorical columns (including combo features)\n",
        "categorical_cols = ['AIRLINE', 'ORIGIN', 'DEST']\n",
        "# Ensure they exist in the dataset\n",
        "categorical_cols = [col for col in categorical_cols if col in X.columns]\n",
        "# Make sure categorical columns are strings\n",
        "for col in categorical_cols:\n",
        "    X[col] = X[col].astype(str)\n",
        "\n",
        "# Drop any remaining object columns that are not categorical\n",
        "for col in X.select_dtypes(include='object').columns:\n",
        "    if col not in categorical_cols:\n",
        "        X = X.drop(columns=col)\n",
        "\n",
        "# Train-validation-test split (60-20-20)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "# Categorical feature indices for CatBoost\n",
        "categorical_features_indices = [i for i, f in enumerate(X_train.columns) if f in categorical_cols]\n",
        "\n",
        "# CatBoost Regressor\n",
        "catboost_model = CatBoostRegressor(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    loss_function='RMSE',\n",
        "    eval_metric='RMSE',\n",
        "    cat_features=categorical_features_indices,\n",
        "    random_seed=42,\n",
        "    verbose=100\n",
        ")\n",
        "\n",
        "# Train with early stopping\n",
        "catboost_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    early_stopping_rounds=100,\n",
        "    plot=False,\n",
        "    verbose_eval=100\n",
        ")\n",
        "\n",
        "# Output best iteration and validation RMSE\n",
        "best_iter = catboost_model.best_iteration_\n",
        "best_val_rmse = catboost_model.best_score_['validation']['RMSE']\n",
        "\n",
        "print(f\"CatBoost trained successfully\")\n",
        "print(f\"Best iteration: {best_iter}\")\n",
        "print(f\"Validation RMSE: {best_val_rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eFcD2PjS1Lt",
        "outputId": "33cbc499-2e8f-499c-f1b5-dfe69fc1a2d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 51.1778546\ttest: 50.8353748\tbest: 50.8353748 (0)\ttotal: 2.08s\tremaining: 34m 34s\n",
            "100:\tlearn: 50.1170703\ttest: 49.8015020\tbest: 49.8015020 (100)\ttotal: 1m 50s\tremaining: 16m 25s\n",
            "200:\tlearn: 50.0224871\ttest: 49.7353731\tbest: 49.7353731 (200)\ttotal: 3m 31s\tremaining: 14m\n",
            "300:\tlearn: 49.9517417\ttest: 49.6949179\tbest: 49.6949179 (300)\ttotal: 5m 19s\tremaining: 12m 22s\n",
            "400:\tlearn: 49.8834018\ttest: 49.6668621\tbest: 49.6668621 (400)\ttotal: 7m 13s\tremaining: 10m 46s\n",
            "500:\tlearn: 49.8311620\ttest: 49.6472218\tbest: 49.6472218 (500)\ttotal: 9m 8s\tremaining: 9m 6s\n",
            "600:\tlearn: 49.7848663\ttest: 49.6302879\tbest: 49.6302879 (600)\ttotal: 11m 2s\tremaining: 7m 19s\n",
            "700:\tlearn: 49.7413756\ttest: 49.6155120\tbest: 49.6155120 (700)\ttotal: 12m 56s\tremaining: 5m 31s\n",
            "800:\tlearn: 49.7019243\ttest: 49.6046328\tbest: 49.6043773 (799)\ttotal: 14m 44s\tremaining: 3m 39s\n",
            "900:\tlearn: 49.6589718\ttest: 49.5967088\tbest: 49.5965843 (898)\ttotal: 16m 39s\tremaining: 1m 49s\n",
            "999:\tlearn: 49.6230117\ttest: 49.5877387\tbest: 49.5877387 (999)\ttotal: 18m 33s\tremaining: 0us\n",
            "\n",
            "bestTest = 49.58773873\n",
            "bestIteration = 999\n",
            "\n",
            "CatBoost trained successfully\n",
            "Best iteration: 999\n",
            "Validation RMSE: 49.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
        "\n",
        "def airline_delay_categories(delay):\n",
        "    if pd.isna(delay):\n",
        "        return 'Unknown'\n",
        "    elif delay <= 15:\n",
        "        return 'On_Time'\n",
        "    elif delay <= 60:\n",
        "        return 'Minor_Delay'\n",
        "    elif delay <= 240:\n",
        "        return 'Major_Delay'\n",
        "    else:\n",
        "        return 'Severe_Delay'\n",
        "\n",
        "def evaluate_model(y_true, y_pred, dataset_name):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    y_true_cat = [airline_delay_categories(d) for d in y_true]\n",
        "    y_pred_cat = [airline_delay_categories(d) for d in y_pred]\n",
        "    category_acc = accuracy_score(y_true_cat, y_pred_cat)\n",
        "\n",
        "    binary_acc = accuracy_score((y_true > 15), (y_pred > 15))\n",
        "\n",
        "    print(f\"{dataset_name} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R²: {r2:.4f}, \"\n",
        "          f\"4-cat Acc: {category_acc:.3f}, Binary Acc: {binary_acc:.3f}\")\n",
        "\n",
        "    return {\"mae\": mae, \"rmse\": rmse, \"r2\": r2,\n",
        "            \"category_accuracy\": category_acc, \"binary_accuracy\": binary_acc}\n",
        "\n",
        "# Predictions\n",
        "train_pred = catboost_model.predict(X_train)\n",
        "val_pred = catboost_model.predict(X_val)\n",
        "test_pred = catboost_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "train_metrics = evaluate_model(y_train, train_pred, \"TRAIN\")\n",
        "val_metrics = evaluate_model(y_val, val_pred, \"VALIDATION\")\n",
        "test_metrics = evaluate_model(y_test, test_pred, \"TEST\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZJF97YGguPg",
        "outputId": "254a5d5b-baf4-4c1f-bd26-84979e4af379"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN - MAE: 22.66, RMSE: 49.63, R²: 0.0656, 4-cat Acc: 0.771, Binary Acc: 0.794\n",
            "VALIDATION - MAE: 22.71, RMSE: 49.59, R²: 0.0545, 4-cat Acc: 0.769, Binary Acc: 0.792\n",
            "TEST - MAE: 22.61, RMSE: 49.45, R²: 0.0546, 4-cat Acc: 0.771, Binary Acc: 0.794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances and align with trained features\n",
        "feature_importances = catboost_model.get_feature_importance()\n",
        "trained_features = catboost_model.feature_names_\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': trained_features,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"Top 15 features by importance:\")\n",
        "for i, row in importance_df.head(15).iterrows():\n",
        "    print(f\"{i+1:2d}. {row['Feature']:<25}: {row['Importance']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TShqqg6OAeE",
        "outputId": "04ccb986-0a7e-49d5-835c-815041ef1e13"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 features by importance:\n",
            "31. AIRLINE_7DAY_AVG         : 23.3561\n",
            "17. DAY_OF_YEAR              : 11.9758\n",
            "15. HOUR_SIN                 : 10.7477\n",
            " 5. DEP_HOUR                 : 8.4653\n",
            " 3. DEST                     : 5.9568\n",
            " 1. AIRLINE                  : 5.8716\n",
            "25. AIRLINE_HISTORICAL_DELAY : 5.6835\n",
            " 2. ORIGIN                   : 5.3478\n",
            " 7. DAY_OF_WEEK              : 3.5127\n",
            "21. DEP_HOUR_FLIGHTS         : 3.3524\n",
            " 4. DISTANCE                 : 3.2533\n",
            "11. IS_SUMMER                : 2.8170\n",
            "26. ROUTE_FREQUENCY          : 2.1527\n",
            "16. HOUR_COS                 : 2.0098\n",
            "29. DISTANCE_TIME_RATIO      : 1.2707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "# Encode categorical features for LightGBM/XGBoost\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_encoded = X_train.copy()\n",
        "X_val_encoded = X_val.copy()\n",
        "X_test_encoded = X_test.copy()\n",
        "\n",
        "for col in ['AIRLINE', 'ORIGIN', 'DEST']:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
        "    X_val_encoded[col] = le.transform(X_val_encoded[col].astype(str))\n",
        "    X_test_encoded[col] = le.transform(X_test_encoded[col].astype(str))\n",
        "\n",
        "# Initialize models\n",
        "lgbm_model = LGBMRegressor(\n",
        "    n_estimators=300, max_depth=8, learning_rate=0.1,\n",
        "    subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1, verbose=-1\n",
        ")\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=300, max_depth=8, learning_rate=0.1,\n",
        "    subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train models\n",
        "lgbm_model.fit(X_encoded, y_train)\n",
        "xgb_model.fit(X_encoded, y_train)\n",
        "\n",
        "# Predictions\n",
        "lgbm_pred = lgbm_model.predict(X_test_encoded)\n",
        "xgb_pred = xgb_model.predict(X_test_encoded)\n",
        "catboost_pred = catboost_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "lgbm_metrics = evaluate_model(y_test, lgbm_pred, \"LIGHTGBM\")\n",
        "xgb_metrics = evaluate_model(y_test, xgb_pred, \"XGBOOST\")\n",
        "catboost_metrics = evaluate_model(y_test, catboost_pred, \"CATBOOST_BASELINE\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgiPczqCGYCm",
        "outputId": "a7aeb29a-c035-4f8e-c846-44e159104a41"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIGHTGBM - MAE: 22.66, RMSE: 49.49, R²: 0.0534, 4-cat Acc: 0.772, Binary Acc: 0.794\n",
            "XGBOOST - MAE: 22.67, RMSE: 49.55, R²: 0.0512, 4-cat Acc: 0.768, Binary Acc: 0.792\n",
            "CATBOOST_BASELINE - MAE: 22.61, RMSE: 49.45, R²: 0.0546, 4-cat Acc: 0.771, Binary Acc: 0.794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === OVERFITTING DETECTION ===\n",
        "print(\"Checking for overfitting...\")\n",
        "\n",
        "# Compare training vs validation performance\n",
        "print(f\"Training MAE: {train_metrics['mae']:.2f} | Validation MAE: {val_metrics['mae']:.2f} | Test MAE: {test_metrics['mae']:.2f}\")\n",
        "print(f\"Training 4-Category Accuracy: {train_metrics['category_accuracy']:.1%} | Validation: {val_metrics['category_accuracy']:.1%} | Test: {test_metrics['category_accuracy']:.1%}\")\n",
        "\n",
        "# Calculate gaps\n",
        "mae_gap = val_metrics['mae'] - train_metrics['mae']\n",
        "acc_gap = train_metrics['category_accuracy'] - val_metrics['category_accuracy']\n",
        "\n",
        "print(f\"MAE Gap (Validation - Training): {mae_gap:.2f}\")\n",
        "print(f\"Accuracy Gap (Training - Validation): {acc_gap:.3f}\")\n",
        "\n",
        "# Risk assessment\n",
        "if mae_gap < 2.0 and acc_gap < 0.05:\n",
        "    print(\"LOW OVERFITTING RISK\")\n",
        "elif mae_gap < 5.0 and acc_gap < 0.10:\n",
        "    print(\"MODERATE OVERFITTING\")\n",
        "else:\n",
        "    print(\"HIGH OVERFITTING RISK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bamsSXm5je4h",
        "outputId": "4092dc99-b2f7-4039-f224-74dc5ecf8403"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for overfitting...\n",
            "Training MAE: 22.66 | Validation MAE: 22.71 | Test MAE: 22.61\n",
            "Training 4-Category Accuracy: 77.1% | Validation: 76.9% | Test: 77.1%\n",
            "MAE Gap (Validation - Training): 0.06\n",
            "Accuracy Gap (Training - Validation): 0.002\n",
            "LOW OVERFITTING RISK\n"
          ]
        }
      ]
    }
  ]
}